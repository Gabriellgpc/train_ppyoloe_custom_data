{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Load model with pretrained weights\n",
    "from super_gradients.training import models\n",
    "from super_gradients.common.object_names import Models\n",
    "\n",
    "model = models.get(Models.PP_YOLOE_S, pretrained_weights=\"coco\")\n",
    "\n",
    "# Prepare model for conversion\n",
    "# Input size is in format of [Batch x Channels x Width x Height] where 640 is the standard COCO dataset dimensions\n",
    "\n",
    "model.eval()\n",
    "    \n",
    "# Create dummy_input\n",
    "dummy_input = torch.rand(size=[1, 3, 640, 640])\n",
    "\n",
    "# Convert model to onnx\n",
    "torch.onnx.export(model, dummy_input,  \"/workspace/pp-yoloe-s-custom-sg.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict('/datasets/cat/images/IMG_20210726_161004.jpg').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/datasets/cat/images/IMG_20210726_161004.jpg'\n",
    "image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, size=640):\n",
    "    # resize\n",
    "    image = cv2.resize(image, dsize=[size,size])\n",
    "    # standardize\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    # normalize, COCO mean and std\n",
    "    image = (image - np.array([123.675, 116.28, 103.53])) / np.array([58.395,  57.12,  57.375])\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    image = np.transpose( image, (2, 0, 1))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return torch.from_numpy(image.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_out = model._get_pipeline()(image)\n",
    "bbox = pip_out[0].prediction.bboxes_xyxy\n",
    "confidence = pip_out[0].prediction.confidence\n",
    "labels = pip_out[0].prediction.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = bbox[0][:2].astype('int')\n",
    "p2 = bbox[0][2:].astype('int')\n",
    "cv2.rectangle(image, pt1=p1, pt2=p2, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = preprocess_image(image)\n",
    "\n",
    "# input_image = model._get_pipeline()(image)\n",
    "\n",
    "model_output = model.forward( input_image )\n",
    "predictions = model_output[0]\n",
    "\n",
    "\n",
    "cls_thrs = 0.5\n",
    "nms_iout = 0.7\n",
    "\n",
    "for pred_bboxes, pred_scores in zip(*predictions):\n",
    "    # pred_bboxes [Anchors, 4],\n",
    "    # pred_scores [Anchors, C]\n",
    "    print(pred_bboxes.shape)\n",
    "    print(pred_scores.shape)\n",
    "\n",
    "    # filter by score_thrs\n",
    "    pred_cls_conf, pred_cls_label = torch.max(pred_scores, dim=1)\n",
    "    print(pred_cls_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "\n",
    "# onnx_model = onnx.load(\"/workspace/pp-yoloe-s-custom-sg.onnx\")\n",
    "# onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = dummy_input\n",
    "# torch_out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnxruntime\n",
    "# import numpy as np\n",
    "\n",
    "# ort_session = onnxruntime.InferenceSession(\"/workspace/pp-yoloe-s-custom-sg.onnx\")\n",
    "\n",
    "# def to_numpy(tensor):\n",
    "#     return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# # compute ONNX Runtime output prediction\n",
    "# ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "# ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# # compare ONNX Runtime and PyTorch results\n",
    "# np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "# print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
